{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from repsim.benchmark.paths import EXPERIMENT_RESULTS_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/root/similaritybench/experiments/results/nlp_aug_mnli_full.csv\"\n",
    "# path = \"/root/similaritybench/experiments/results/nlp_sc_mnli_full.csv\"\n",
    "\n",
    "\n",
    "cleaned_dfs = []\n",
    "for path, setting, dataset in [\n",
    "        (\"/root/similaritybench/experiments/results/nlp_aug_sst2.csv\", \"aug\", \"sst2\"),\n",
    "        (\"/root/similaritybench/experiments/results/nlp_mem_sst2.csv\", \"mem\", \"sst2\"),\n",
    "        (\"/root/similaritybench/experiments/results/nlp_shortcut_sst2.csv\", \"sc\", \"sst2\"),\n",
    "        (\"/root/similaritybench/experiments/results/nlp_shortcut_mnli.csv\", \"sc\", \"mnli\"),\n",
    "        (\"/root/similaritybench/experiments/results/nlp_aug_mnli.csv\", \"aug\", \"mnli\"),\n",
    "        (\"/root/similaritybench/experiments/results/nlp_mem_mnli.csv\", \"mem\", \"mnli\"),\n",
    "    ]:\n",
    "    print(setting, dataset)\n",
    "    df = pd.read_csv(path)\n",
    "    data = df.loc[2:].copy().reset_index(drop=True)\n",
    "    print(data.columns)\n",
    "    proper_name = {\"quality_measure\": \"Similarity Measure\", \"AUPRC\": \"AUPRC\", \"violation_rate\": \"Violation Rate\"}\n",
    "    data.columns = [proper_name[col] for col in data.columns]\n",
    "    data[\"Architecture\"] = \"BERT-Base\"\n",
    "    data.loc[:, \"Violation Rate\"] = data.loc[:, \"Violation Rate\"].astype(float)\n",
    "    data.loc[:, \"AUPRC\"] = data.loc[:, \"AUPRC\"].astype(float)\n",
    "    data = data.melt(\n",
    "        id_vars=[\"Similarity Measure\", \"Architecture\"],\n",
    "        value_vars=[\"Violation Rate\", \"AUPRC\"],\n",
    "        var_name=\"Quality Metric\",\n",
    "        value_name=\"Score\",\n",
    "    )\n",
    "    data[\"Setting\"] = setting\n",
    "    data[\"Dataset\"] = dataset\n",
    "\n",
    "    cleaned_dfs.append(data)\n",
    "\n",
    "data = pd.concat(cleaned_dfs).reset_index(drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for setting in data.Setting.unique():\n",
    "    pivot = pd.pivot(data[data.Setting == setting], index=\"Similarity Measure\", columns=[\"Quality Metric\", \"Dataset\"], values=\"Score\")\n",
    "    print(pivot.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = data.pivot_table(index=\"Similarity Measure\", columns=[\"Quality Metric\", \"Setting\", \"Dataset\"], values=\"Score\")\n",
    "pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styled = pd.io.formats.style.Styler(\n",
    "    pivot,\n",
    "    precision=3,\n",
    "    caption=\"Ability to separate groups of BERT representations in different settings.\",\n",
    ")\n",
    "styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_str = styled.to_latex(hrules=True, position=\"t\", label=\"tab:nlp_groupsep\")\n",
    "latex_str = latex_str.split(\"\\n\")\n",
    "latex_str = [r\"\\rowcolor{Gray}\" + line  if i>=12 and (i-12)%2==0 else line for i, line in enumerate(latex_str[:-4])] + latex_str[-4:]\n",
    "latex_str = \"\\n\".join(latex_str)\n",
    "print(latex_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupsep_data = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dfs = []\n",
    "for path, setting, dataset in [\n",
    "    (\"/root/similaritybench/experiments/results/correlation_nlp_aug_mnli_full.csv\",\"aug\",\"mnli\"),\n",
    "    (\"/root/similaritybench/experiments/results/correlation_nlp_aug_sst2_full.csv\",\"aug\",\"sst2\"),\n",
    "    (\"/root/similaritybench/experiments/results/correlation_nlp_mem_mnli_full.csv\",\"mem\",\"mnli\"),\n",
    "    (\"/root/similaritybench/experiments/results/correlation_nlp_mem_sst2_full.csv\",\"mem\",\"sst2\"),\n",
    "    (\"/root/similaritybench/experiments/results/correlation_nlp_sc_mnli_full.csv\",\"sc\",\"mnli\"),\n",
    "    (\"/root/similaritybench/experiments/results/correlation_nlp_sc_sst2_full.csv\",\"sc\",\"sst2\"),\n",
    "    ]:\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    df[\"Setting\"] = setting\n",
    "    df[\"Dataset\"] = dataset\n",
    "    cleaned_dfs.append(df)\n",
    "data = pd.concat(cleaned_dfs).reset_index(drop=True)\n",
    "data = data.rename(columns={\"functional_similarity_measure\": \"Functional Similarity Measure\", \"similarity_measure\": \"Representational Similarity Measure\", \"quality_measure\": \"Quality Measure\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = data[data[\"Quality Measure\"]==\"spearmanr\"].pivot_table(index=\"Representational Similarity Measure\",columns=[\"Functional Similarity Measure\", \"Quality Measure\", \"Setting\", \"Dataset\"],values=\"corr\")\n",
    "# pivot = pivot.apply(abs)\n",
    "pivot = pivot.sort_values(by=\"Representational Similarity Measure\")\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styled = pd.io.formats.style.Styler(\n",
    "    pivot,\n",
    "    precision=3,\n",
    "    caption=\"Absolute correlation between representational and functional similarity for BERT models.\",\n",
    ")\n",
    "latex_str = styled.to_latex(hrules=True, position=\"t\", label=\"tab:nlp_outputcorr\", )\n",
    "latex_str = latex_str.split(\"\\n\")\n",
    "latex_str = [r\"\\rowcolor{Gray}\" + line  if i>=12 and (i-12)%2==0 else line for i, line in enumerate(latex_str[:-4])] + latex_str[-4:]\n",
    "latex_str = \"\\n\".join(latex_str)\n",
    "print(latex_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmeasures = [\"kendalltau\"]\n",
    "# qmeasures = [\"pearsonr\"]\n",
    "# qmeasures = [\"kendalltau\", \"spearmanr\"]\n",
    "pivot = data[data[\"Quality Measure\"].isin(qmeasures)].pivot_table(index=\"Representational Similarity Measure\",columns=[\"Quality Measure\", \"Setting\", \"Dataset\", \"Functional Similarity Measure\", \"architecture\", ],values=\"corr\")\n",
    "pivot = pivot.apply(abs)\n",
    "pivot = pivot.sort_values(by=\"Representational Similarity Measure\")\n",
    "pivot.corr(\"kendall\")\n",
    "# pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Quality Measure\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data = data.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Table (with preliminary values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_setting = \"aug\"\n",
    "corr_qmeasure = \"spearmanr\"\n",
    "corr_funcsim = \"JSD\"\n",
    "corr_dataset = \"mnli\"\n",
    "\n",
    "merge_corr = corr_data.loc[\n",
    "    (corr_data[\"Functional Similarity Measure\"] == corr_funcsim) &\n",
    "    (corr_data[\"Quality Measure\"]==corr_qmeasure) &\n",
    "    (corr_data[\"Setting\"] == corr_setting) &\n",
    "    (corr_data[\"Dataset\"] == corr_dataset)\n",
    "]\n",
    "merge_corr[\"Score\"] = merge_corr.loc[:, \"corr\"]\n",
    "merge_corr.loc[:, \"Similarity Measure\"] = merge_corr.loc[:, \"Representational Similarity Measure\"]\n",
    "merge_corr.loc[:, \"Setting\"] = corr_funcsim+corr_dataset+corr_setting\n",
    "full_corr_setting = corr_funcsim+corr_dataset+corr_setting\n",
    "merge_corr.loc[:, \"Architecture\"] = \"BERT-Base\"\n",
    "merge_corr.loc[:, \"Quality Metric\"] = corr_qmeasure\n",
    "\n",
    "group_dataset = \"mnli\"\n",
    "group_qmeasure = \"AUPRC\"\n",
    "merge_groups = groupsep_data.loc[\n",
    "    (groupsep_data[\"Dataset\"] == group_dataset) &\n",
    "    (groupsep_data[\"Quality Metric\"] == group_qmeasure)\n",
    "]\n",
    "\n",
    "merged = pd.concat([merge_groups, merge_corr], axis=0)\n",
    "merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_to_abbrv = {\n",
    "    \"AlignedCosineSimilarity\": \"AlignCos\",\n",
    "    \"CKA\": \"CKA\",\n",
    "    \"ConcentricityDifference\": \"ConcDiff\",\n",
    "    \"DistanceCorrelation\": \"DistCorr\",\n",
    "    \"EigenspaceOverlapScore\": \"EOS\",\n",
    "    \"GeometryScore\": \"GS\",\n",
    "    \"Gulp\": \"GULP\",\n",
    "    \"HardCorrelationMatch\": \"HardCorr\",\n",
    "    \"IMDScore\": \"IMD\",\n",
    "    \"JaccardSimilarity\": \"Jaccard\",\n",
    "    \"LinearRegression\": \"LinReg\",\n",
    "    \"MagnitudeDifference\": \"MagDiff\",\n",
    "    \"OrthogonalAngularShapeMetricCentered\": \"AngShape\",\n",
    "    \"OrthogonalProcrustesCenteredAndNormalized\": \"OrthProc\",\n",
    "    \"PWCCA\": \"PWCCA\",\n",
    "    \"PermutationProcrustes\": \"PermProc\",\n",
    "    \"ProcrustesSizeAndShapeDistance\": \"ProcDist\",\n",
    "    \"RSA\": \"RSA\",\n",
    "    \"RSMNormDifference\": \"RSMDiff\",\n",
    "    \"RankSimilarity\": \"RankSim\",\n",
    "    \"SVCCA\": \"SVCCA\",\n",
    "    \"SecondOrderCosineSimilarity\": \"2nd-Cos\",\n",
    "    \"SoftCorrelationMatch\": \"SoftCorr\",\n",
    "    \"UniformityDifference\": \"UnifDiff\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_vision_data = merged.copy()\n",
    "fake_vision_data.loc[:, \"Architecture\"] = \"ResNetX\"\n",
    "fake_vision_data.loc[:, \"Dataset\"] = \"ImageNet100\"\n",
    "\n",
    "fake_graph_data = merged.copy()\n",
    "fake_graph_data.loc[:, \"Architecture\"] = \"GraphSage\"\n",
    "fake_graph_data.loc[:, \"Dataset\"] = \"ogbn-arxiv\"\n",
    "\n",
    "table_data = pd.concat([merged, fake_vision_data, fake_graph_data])\n",
    "table_data[\"Similarity Measure\"] = table_data[\"Similarity Measure\"].map(measure_to_abbrv)\n",
    "\n",
    "\n",
    "table_data.loc[table_data.Setting == full_corr_setting, \"Score\"] = -1 * table_data.loc[table_data.Setting == full_corr_setting, \"Score\"]\n",
    "\n",
    "pivot = pd.pivot_table(table_data, index=\"Similarity Measure\",columns=[\"Setting\", \"Quality Metric\", \"Architecture\", \"Dataset\"], values=\"Score\")\n",
    "pivot = pivot.sort_values(by=\"Similarity Measure\")\n",
    "\n",
    "styled = pd.io.formats.style.Styler(\n",
    "    pivot,\n",
    "    precision=3,\n",
    "    caption=\"Results overview for selected datasets and models.\",\n",
    ")\n",
    "\n",
    "latex_str = styled.to_latex(hrules=True, position=\"t\", label=\"tab:result_overview\", )\n",
    "latex_str = latex_str.split(\"\\n\")\n",
    "latex_str = [r\"\\rowcolor{Gray}\" + line  if i>=12 and (i-12)%2==0 else line for i, line in enumerate(latex_str[:-4])] + latex_str[-4:]\n",
    "latex_str = \"\\n\".join(latex_str)\n",
    "print(latex_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Table (Paper Version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pandas.io.formats.style\n",
    "\n",
    "\n",
    "measure_to_abbrv = {\n",
    "    \"AlignedCosineSimilarity\": \"AlignCos\",\n",
    "    \"CKA\": \"CKA\",\n",
    "    \"ConcentricityDifference\": \"ConcDiff\",\n",
    "    \"DistanceCorrelation\": \"DistCorr\",\n",
    "    \"EigenspaceOverlapScore\": \"EOS\",\n",
    "    \"GeometryScore\": \"GS\",\n",
    "    \"Gulp\": \"GULP\",\n",
    "    \"HardCorrelationMatch\": \"HardCorr\",\n",
    "    \"IMDScore\": \"IMD\",\n",
    "    \"JaccardSimilarity\": \"Jaccard\",\n",
    "    \"LinearRegression\": \"LinReg\",\n",
    "    \"MagnitudeDifference\": \"MagDiff\",\n",
    "    \"OrthogonalAngularShapeMetricCentered\": \"AngShape\",\n",
    "    \"OrthogonalProcrustesCenteredAndNormalized\": \"OrthProc\",\n",
    "    \"PWCCA\": \"PWCCA\",\n",
    "    \"PermutationProcrustes\": \"PermProc\",\n",
    "    \"ProcrustesSizeAndShapeDistance\": \"ProcDist\",\n",
    "    \"RSA\": \"RSA\",\n",
    "    \"RSMNormDifference\": \"RSMDiff\",\n",
    "    \"RankSimilarity\": \"RankSim\",\n",
    "    \"SVCCA\": \"SVCCA\",\n",
    "    \"SecondOrderCosineSimilarity\": \"2nd-Cos\",\n",
    "    \"SoftCorrelationMatch\": \"SoftCorr\",\n",
    "    \"UniformityDifference\": \"UnifDiff\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dfs = []\n",
    "nlp_root = Path(\"/root/similaritybench/experiments/paper_results/nlp\")\n",
    "for path in nlp_root.iterdir():\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    setting = path.name.split(\"_\")[0]\n",
    "\n",
    "    pattern = r'(?<=_)sst2(?=_)|(?<=_)mnli(?=_)'\n",
    "    match = re.search(pattern, path.name)\n",
    "    assert match is not None\n",
    "    dataset = match.group(0)\n",
    "\n",
    "    df[\"Setting\"] = setting\n",
    "    df[\"Dataset\"] = dataset\n",
    "    cleaned_dfs.append(df)\n",
    "\n",
    "data = pd.concat(cleaned_dfs).reset_index(drop=True)\n",
    "nlp_data = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dfs = []\n",
    "root = Path(\"/root/similaritybench/experiments/paper_results/graph\")\n",
    "for path in root.iterdir():\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    pattern = r\"augmentation|label_test|layer_test|output_correlation|shortcut\"\n",
    "    match = re.search(pattern, path.name)\n",
    "    pattern_to_setting = {\n",
    "        \"augmentation\": \"aug\",\n",
    "        \"label_test\": \"mem\",\n",
    "        \"layer_test\": \"mono\",\n",
    "        \"output_correlation\": \"correlation\",\n",
    "        \"shortcut\": \"sc\",\n",
    "    }\n",
    "    setting = pattern_to_setting[match.group(0)]\n",
    "\n",
    "    pattern = r\"(?<=_)cora(?=_)|(?<=_)flickr(?=_)|(?<=_)ogbn-arxiv(?=_)\"\n",
    "    match = re.search(pattern, path.name)\n",
    "    assert match is not None\n",
    "    dataset = match.group(0)\n",
    "\n",
    "    df[\"Setting\"] = setting\n",
    "    df[\"Dataset\"] = dataset\n",
    "    cleaned_dfs.append(df)\n",
    "\n",
    "data = pd.concat(cleaned_dfs).reset_index(drop=True)\n",
    "graph_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dfs = []\n",
    "root = Path(\"/root/similaritybench/experiments/paper_results/vision\")\n",
    "for path in root.iterdir():\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    pattern = r\"aug|mem|mono|correlation|sc\"\n",
    "    match = re.search(pattern, path.name)\n",
    "    pattern_to_setting = {\n",
    "        \"aug\": \"aug\",\n",
    "        \"mem\": \"mem\",\n",
    "        \"mono\": \"mono\",\n",
    "        \"correlation\": \"correlation\",\n",
    "        \"sc\": \"sc\",\n",
    "    }\n",
    "    setting = pattern_to_setting[match.group(0)]\n",
    "\n",
    "    pattern = r\"(?<=_)in100(?=_)\"\n",
    "    match = re.search(pattern, path.name)\n",
    "    assert match is not None\n",
    "    dataset = match.group(0)\n",
    "\n",
    "    df[\"Setting\"] = setting\n",
    "    df[\"Dataset\"] = dataset\n",
    "    cleaned_dfs.append(df)\n",
    "\n",
    "data = pd.concat(cleaned_dfs).reset_index(drop=True)\n",
    "vision_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"/root/similaritybench/experiments/paper_results/vision/mono_in100_full.csv\", index_col=0)\n",
    "# df.unstack().reset_index(level=0)\n",
    "# # df.melt(value_vars=[\"correlation\"] + [f\"correlation.{i}\" for i in range(1, 7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([nlp_data, graph_data, vision_data])\n",
    "print(data.columns)\n",
    "\n",
    "data = data.rename(columns={\"functional_similarity_measure\": \"Functional Similarity Measure\", \"similarity_measure\": \"Representational Similarity Measure\", \"quality_measure\": \"Quality Measure\"})\n",
    "\n",
    "idx = data.Setting == \"correlation\"\n",
    "data.loc[idx, \"value\"] = data.loc[idx, \"corr\"]\n",
    "\n",
    "idx = (data.Setting == \"correlation\") & (data[\"Functional Similarity Measure\"] == \"AbsoluteAccDiff\")\n",
    "data.loc[idx, \"Setting\"] = \"acc_corr\"\n",
    "\n",
    "idx = (data.Setting == \"correlation\") & (data[\"Functional Similarity Measure\"] != \"JSD\")\n",
    "data = data.loc[~idx]\n",
    "\n",
    "idx = (data.Setting.isin([\"aug\", \"mem\", \"sc\"])) & (data[\"Quality Measure\"] != \"AUPRC\")\n",
    "data = data.loc[~idx]\n",
    "\n",
    "idx = (data.Setting.isin([\"correlation\", \"acc_corr\"])) & (data[\"Quality Measure\"] != \"spearmanr\")\n",
    "data = data.loc[~idx]\n",
    "\n",
    "idx = (data.Setting.isin([\"mono\"])) & (data[\"Quality Measure\"] != \"correlation\")\n",
    "data = data.loc[~idx]\n",
    "\n",
    "\n",
    "def beautify_df(data):\n",
    "    data.loc[:, \"Representational Similarity Measure\"] = data[\"Representational Similarity Measure\"].map(\n",
    "        measure_to_abbrv\n",
    "    )\n",
    "    data.loc[:, \"architecture\"] = data[\"architecture\"].map(\n",
    "        {\n",
    "            \"BERT-L\": \"BERT\",\n",
    "            \"GCN\": \"GCN\",\n",
    "            \"GAT\": \"GAT\",\n",
    "            \"GraphSAGE\": \"SAGE\",\n",
    "            \"VGG11\": \"VGG11\",\n",
    "            \"VGG19\": \"VGG19\",\n",
    "            \"ResNet18\": \"RNet18\",\n",
    "            \"ResNet34\": \"RNet34\",\n",
    "            \"ResNet101\": \"RNet101\",\n",
    "            \"ViT_B32\": \"ViT_B32\",\n",
    "            \"ViT_L32\": \"ViT_L32\",\n",
    "        }\n",
    "    )\n",
    "    data.loc[:, \"domain\"] = data[\"domain\"].map({\"NLP\": \"Text\", \"GRAPHS\": \"Graph\", \"VISION\": \"Vision\"})\n",
    "    data.loc[:, \"Dataset\"] = data[\"Dataset\"].map(\n",
    "        {\n",
    "            \"mnli_aug_rate0\": \"MNLI\",\n",
    "            \"mnli_mem_rate0\": \"MNLI\",\n",
    "            \"mnli\": \"MNLI\",\n",
    "            \"sst2_sc_rate0558\": \"SST2\",\n",
    "            \"sst2_mem_rate0\": \"SST2\",\n",
    "            \"mnli_sc_rate0354\": \"MNLI\",\n",
    "            \"sst2_aug_rate0\": \"SST2\",\n",
    "            \"sst2\": \"SST2\",\n",
    "            \"flickr\": \"flickr\",\n",
    "            \"ogbn-arxiv\": \"arXiv\",\n",
    "            \"cora\": \"Cora\",\n",
    "            \"in100\": \"IN100\"\n",
    "        }\n",
    "    )\n",
    "    data.loc[:, \"Setting\"] = data[\"Setting\"].map(\n",
    "        {\n",
    "            \"aug\": \"Augmentation\",\n",
    "            \"mem\": \"Random Labels\",\n",
    "            \"correlation\": \"JSD Corr.\",\n",
    "            \"acc_corr\": \"Acc Corr.\",\n",
    "            \"mono\": \"Layer Mono.\",\n",
    "            \"sc\": \"Shortcuts\",\n",
    "        }\n",
    "    )\n",
    "    column_order = [\"Acc Corr.\", \"JSD Corr.\", \"Random Labels\", \"Shortcuts\", \"Augmentation\", \"Layer Mono.\"]\n",
    "    data.loc[:, \"Setting\"] = pd.Categorical(\n",
    "        data[\"Setting\"],\n",
    "        categories=column_order,\n",
    "        ordered=True,\n",
    "    )\n",
    "    data.loc[:, \"Quality Measure\"] = data[\"Quality Measure\"].map(\n",
    "        {\"violation_rate\": \"Conformity Rate\", \"AUPRC\": \"AUPRC\", \"spearmanr\": \"Spearman\", \"correlation\": \"Spearman\"}\n",
    "    )\n",
    "    data.loc[data[\"Quality Measure\"] == \"Conformity Rate\", \"value\"] = (\n",
    "        1 - data.loc[data[\"Quality Measure\"] == \"Conformity Rate\", \"value\"]\n",
    "    )  # must be run in conjunction with the above renaming\n",
    "\n",
    "    data = data.rename(\n",
    "        columns={\n",
    "            \"domain\": \"Modality\",\n",
    "            \"architecture\": \"Arch.\",\n",
    "            \"Representational Similarity Measure\": \"Sim Meas.\",\n",
    "            \"Quality Measure\": \"Eval.\",\n",
    "            \"Setting\": \"Scenario\",\n",
    "        }\n",
    "    )\n",
    "    data.loc[data.Scenario.isin([\"Acc Corr.\", \"JSD Corr.\"]), \"Type\"] = \"Grounding by Prediction\"\n",
    "    data.loc[data.Scenario.isin([\"Random Labels\", \"Shortcuts\", \"Augmentation\", \"Layer Mono.\"]), \"Type\"] = (\n",
    "        \"Grounding by Design\"\n",
    "    )\n",
    "    return data, column_order\n",
    "\n",
    "\n",
    "data, column_order = beautify_df(data)\n",
    "# Data Selection for Overview Table\n",
    "idx = data[\"Dataset\"].isin([\"MNLI\", \"flickr\", \"IN100\"]) & data[\"Arch.\"].isin([\"SAGE\", \"BERT\", \"RNet18\"])\n",
    "\n",
    "pivot = pd.pivot_table(\n",
    "    data.loc[idx],\n",
    "    index=\"Sim Meas.\",\n",
    "    columns=[\"Type\", \"Scenario\", \"Eval.\", \"Modality\", \"Dataset\", \"Arch.\"],\n",
    "    values=\"value\",\n",
    ")\n",
    "pivot = pivot.sort_values(by=\"Sim Meas.\")\n",
    "pivot = pivot.reindex(column_order, axis=\"columns\", level=\"Scenario\")\n",
    "pivot = pivot.reindex([\"Grounding by Prediction\", \"Grounding by Design\"], axis=\"columns\", level=\"Type\")\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styled = pd.io.formats.style.Styler(\n",
    "    pivot,\n",
    "    precision=2,\n",
    "    caption=\"Full Results.\",\n",
    ")\n",
    "\n",
    "# highlight top 3 values (best red)\n",
    "# latex_str = styled.highlight_quantile(q_left=0.86, axis=0, props=\"textbf:--rwrap;\").to_latex(hrules=True, position=\"t\", label=\"tab:result_overview\", )  #top 3\n",
    "# latex_str = styled.highlight_max(axis=0, props=\"textcolor{red}:--rwrap;\").to_latex(hrules=True, position=\"t\", label=\"tab:result_overview\", )  # top1\n",
    "latex_str = styled.highlight_max(axis=0, props=\"textbf:--rwrap;\").to_latex(hrules=True, position=\"t\", label=\"tab:result_overview\", )  # top1\n",
    "\n",
    "\n",
    "# ----- Manual modifications --------\n",
    "latex_str = latex_str.split(\"\\n\")\n",
    "\n",
    "# Center headers\n",
    "pattern = r'\\{r\\}'\n",
    "replacement = r'{c}'\n",
    "# latex_str = [re.sub(pattern, replacement, line) if i in [5, 6] else line for i, line in enumerate(latex_str) ]  # if no type row\n",
    "latex_str = [re.sub(pattern, replacement, line) if i in [5, 6, 7] else line for i, line in enumerate(latex_str) ]\n",
    "\n",
    "# Remove measure row\n",
    "# latex_str.pop(10)  # if no type row\n",
    "latex_str.pop(11)\n",
    "\n",
    "# Add vertical bars\n",
    "line_no = 3\n",
    "mod_line = latex_str[line_no][:17] + \"\".join([\"|rrr\"] * 6) + \"}\"\n",
    "latex_str[line_no] = mod_line\n",
    "\n",
    "# Make every second row gray\n",
    "latex_str = [r\"\\rowcolor{Gray}\" + line  if i>=12 and (i-12)%2==0 else line for i, line in enumerate(latex_str[:-4])] + latex_str[-4:]\n",
    "latex_str = \"\\n\".join(latex_str)\n",
    "print(latex_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dfs = []\n",
    "nlp_root = Path(\"/root/similaritybench/experiments/paper_results/nlp\")\n",
    "for path in nlp_root.iterdir():\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    setting = path.name.split(\"_\")[0]\n",
    "\n",
    "    pattern = r'(?<=_)sst2(?=_)|(?<=_)mnli(?=_)'\n",
    "    match = re.search(pattern, path.name)\n",
    "    assert match is not None\n",
    "    dataset = match.group(0)\n",
    "\n",
    "    df[\"Setting\"] = setting\n",
    "    df[\"Dataset\"] = dataset\n",
    "    cleaned_dfs.append(df)\n",
    "\n",
    "data = pd.concat(cleaned_dfs).reset_index(drop=True)\n",
    "data = data.rename(columns={\"functional_similarity_measure\": \"Functional Similarity Measure\", \"similarity_measure\": \"Representational Similarity Measure\", \"quality_measure\": \"Quality Measure\"})\n",
    "\n",
    "data.loc[data.Setting == \"mono\", \"Quality Measure\"].unique()\n",
    "\n",
    "\n",
    "idx = data.Setting == \"correlation\"\n",
    "data.loc[idx, \"value\"] = data.loc[idx, \"corr\"]\n",
    "\n",
    "idx = (data.Setting.isin([\"correlation\", \"acc_corr\"])) & (data[\"Quality Measure\"] != \"spearmanr\")\n",
    "data = data.loc[~idx]\n",
    "\n",
    "idx = data.Setting == \"correlation\"\n",
    "data.loc[idx, \"Setting\"] = data.loc[idx, \"Setting\"] + data.loc[idx, \"Functional Similarity Measure\"]\n",
    "print(data.Setting.unique())\n",
    "\n",
    "# idx = (data.Setting == \"correlation\") & (data[\"Functional Similarity Measure\"] != \"JSD\")\n",
    "# data = data.loc[~idx]\n",
    "\n",
    "# idx = (data.Setting.isin([\"aug\", \"mem\", \"sc\"])) & (data[\"Quality Measure\"] != \"AUPRC\")\n",
    "# data = data.loc[~idx]\n",
    "\n",
    "# idx = (data.Setting.isin([\"mono\"])) & (data[\"Quality Measure\"] != \"correlation\")\n",
    "# data = data.loc[~idx]\n",
    "\n",
    "data.loc[:, \"Representational Similarity Measure\"] = data[\"Representational Similarity Measure\"].map(\n",
    "        measure_to_abbrv\n",
    ")\n",
    "data.loc[:, \"architecture\"] = data[\"architecture\"].map(\n",
    "    {\"BERT-L\": \"BERT\", \"GCN\": \"GCN\", \"GAT\": \"GAT\", \"GraphSAGE\": \"SAGE\"}\n",
    ")\n",
    "data.loc[:, \"domain\"] = data[\"domain\"].map({\"NLP\": \"Text\", \"GRAPHS\": \"Graph\", \"VISION\": \"Vision\"})\n",
    "data.loc[:, \"Dataset\"] = data[\"Dataset\"].map(\n",
    "    {\n",
    "        \"mnli_aug_rate0\": \"MNLI\",\n",
    "        \"mnli_mem_rate0\": \"MNLI\",\n",
    "        \"mnli\": \"MNLI\",\n",
    "        \"sst2_sc_rate0558\": \"SST2\",\n",
    "        \"sst2_mem_rate0\": \"SST2\",\n",
    "        \"mnli_sc_rate0354\": \"MNLI\",\n",
    "        \"sst2_aug_rate0\": \"SST2\",\n",
    "        \"sst2\": \"SST2\",\n",
    "        \"flickr\": \"flickr\",\n",
    "        \"ogbn-arxiv\": \"arXiv\",\n",
    "        \"cora\": \"Cora\",\n",
    "    }\n",
    ")\n",
    "\n",
    "data.loc[:, \"Setting\"] = data[\"Setting\"].map(\n",
    "    {\n",
    "        \"aug\": \"Augmentation\",\n",
    "        \"mem\": \"Random Labels\",\n",
    "        \"correlationJSD\": \"JSD Corr.\",\n",
    "        \"correlationAbsoluteAccDiff\": \"Acc Corr.\",\n",
    "        \"correlationDisagreement\": \"Disagr. Corr.\",\n",
    "        \"mono\": \"Layer Mono.\",\n",
    "        \"sc\": \"Shortcuts\",\n",
    "    }\n",
    ")\n",
    "column_order = [\"Acc Corr.\", \"JSD Corr.\", \"Disagr. Corr.\", \"Random Labels\", \"Shortcuts\", \"Augmentation\", \"Layer Mono.\"]\n",
    "data.loc[:, \"Setting\"] = pd.Categorical(\n",
    "    data[\"Setting\"],\n",
    "    categories=column_order,\n",
    "    ordered=True,\n",
    ")\n",
    "\n",
    "data.loc[:, \"Quality Measure\"] = data[\"Quality Measure\"].map(\n",
    "    {\"violation_rate\": \"Conformity Rate\", \"AUPRC\": \"AUPRC\", \"spearmanr\": \"Spearman\", \"correlation\": \"Spearman\"}\n",
    ")\n",
    "data.loc[data[\"Quality Measure\"] == \"Conformity Rate\", \"value\"] = 1 - data.loc[data[\"Quality Measure\"] == \"Conformity Rate\", \"value\"]  # must be run in conjunction with the above renaming\n",
    "\n",
    "data = data.rename(\n",
    "    columns={\n",
    "        \"domain\": \"Modality\",\n",
    "        \"architecture\": \"Arch.\",\n",
    "        \"Representational Similarity Measure\": \"Sim Meas.\",\n",
    "        \"Quality Measure\": \"Eval.\",\n",
    "        \"Setting\": \"Scenario\",\n",
    "    }\n",
    ")\n",
    "\n",
    "data.loc[data.Scenario.isin([\"Acc Corr.\", \"JSD Corr.\", \"Disagr. Corr.\"]), \"Type\"] = \"Grounding by Prediction\"\n",
    "data.loc[data.Scenario.isin([\"Random Labels\", \"Shortcuts\", \"Augmentation\", \"Layer Mono.\"]), \"Type\"] = (\n",
    "    \"Grounding by Design\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = data.Modality == \"Text\"\n",
    "\n",
    "pivot = pd.pivot_table(\n",
    "    data.loc[idx],\n",
    "    index=\"Sim Meas.\",\n",
    "    columns=[\"Type\", \"Scenario\", \"Eval.\", \"Modality\", \"Dataset\", \"Arch.\"],\n",
    "    # columns=[\"Type\", \"Eval.\", \"Scenario\", \"Modality\", \"Dataset\", \"Arch.\"],\n",
    "    values=\"value\",\n",
    ")\n",
    "pivot = pivot.sort_values(by=[\"Sim Meas.\"])\n",
    "pivot = pivot.reindex(column_order, axis=\"columns\", level=\"Scenario\")\n",
    "pivot = pivot.reindex([\"Grounding by Prediction\", \"Grounding by Design\"], axis=\"columns\", level=\"Type\")\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styled = pd.io.formats.style.Styler(\n",
    "    pivot,\n",
    "    precision=2,\n",
    "    caption=\"Full Results.\",\n",
    ")\n",
    "\n",
    "# highlight top 3 values (best red)\n",
    "# latex_str = styled.highlight_quantile(q_left=0.86, axis=0, props=\"textbf:--rwrap;\").to_latex(hrules=True, position=\"t\", label=\"tab:result_overview\", )  #top 3\n",
    "# latex_str = styled.highlight_max(axis=0, props=\"textcolor{red}:--rwrap;\").to_latex(hrules=True, position=\"t\", label=\"tab:result_overview\", )  # top1\n",
    "latex_str = styled.highlight_max(axis=0, props=\"textbf:--rwrap;\").to_latex(hrules=True, position=\"t\", label=\"tab:result_overview\", )  # top1\n",
    "\n",
    "\n",
    "# ----- Manual modifications --------\n",
    "latex_str = latex_str.split(\"\\n\")\n",
    "\n",
    "# Center headers\n",
    "pattern = r'\\{r\\}'\n",
    "replacement = r'{c}'\n",
    "# latex_str = [re.sub(pattern, replacement, line) if i in [5, 6] else line for i, line in enumerate(latex_str) ]  # if no type row\n",
    "latex_str = [re.sub(pattern, replacement, line) if i in [5, 6, 7] else line for i, line in enumerate(latex_str) ]\n",
    "\n",
    "# Remove measure row\n",
    "# latex_str.pop(10)  # if no type row\n",
    "latex_str.pop(11)\n",
    "\n",
    "# # Add vertical bars\n",
    "# line_no = 3\n",
    "# mod_line = latex_str[line_no][:17] + \"\".join([\"|rrr\"] * 6) + \"}\"\n",
    "# latex_str[line_no] = mod_line\n",
    "\n",
    "# Make every second row gray\n",
    "latex_str = [r\"\\rowcolor{Gray}\" + line  if i>=12 and (i-12)%2==0 else line for i, line in enumerate(latex_str[:-4])] + latex_str[-4:]\n",
    "latex_str = \"\\n\".join(latex_str)\n",
    "print(latex_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rankplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([nlp_data, graph_data, vision_data])\n",
    "data = data.rename(columns={\"functional_similarity_measure\": \"Functional Similarity Measure\", \"similarity_measure\": \"Representational Similarity Measure\", \"quality_measure\": \"Quality Measure\"})\n",
    "data = data.reset_index()\n",
    "\n",
    "idx = data.Setting == \"correlation\"\n",
    "data.loc[idx, \"value\"] = data.loc[idx, \"corr\"]\n",
    "\n",
    "idx = data[\"Quality Measure\"].isin([\"AUPRC\", \"spearmanr\", \"correlation\"])\n",
    "data = data.loc[idx]\n",
    "\n",
    "idx = data.Setting == \"correlation\"\n",
    "data.loc[idx, \"Setting\"] = data.loc[idx, \"Setting\"] + data.loc[idx, \"Functional Similarity Measure\"]\n",
    "\n",
    "idx = ~(data.Setting == \"mono\")\n",
    "data.loc[idx, \"model\"] = \"agg\"\n",
    "\n",
    "\n",
    "data.head(3)\n",
    "data[\"rank\"] = data.groupby([\"domain\", \"Setting\", \"Dataset\", \"architecture\", \"model\"], as_index=True)[\"value\"].rank(ascending=False)\n",
    "data.head(3)\n",
    "data.loc[:, \"Representational Similarity Measure\"] = data[\"Representational Similarity Measure\"].map(\n",
    "    measure_to_abbrv\n",
    ")\n",
    "data.loc[:, \"architecture\"] = data[\"architecture\"].map(\n",
    "    {\n",
    "        \"BERT-L\": \"BERT\",\n",
    "        \"GCN\": \"GCN\",\n",
    "        \"GAT\": \"GAT\",\n",
    "        \"GraphSAGE\": \"SAGE\",\n",
    "        \"VGG11\": \"VGG11\",\n",
    "        \"VGG19\": \"VGG19\",\n",
    "        \"ResNet18\": \"RNet18\",\n",
    "        \"ResNet34\": \"RNet34\",\n",
    "        \"ResNet101\": \"RNet101\",\n",
    "        \"ViT_B32\": \"ViT_B32\",\n",
    "        \"ViT_L32\": \"ViT_L32\",\n",
    "    }\n",
    ")\n",
    "data.loc[:, \"domain\"] = data[\"domain\"].map({\"NLP\": \"Language\", \"GRAPHS\": \"Graph\", \"VISION\": \"Vision\"})\n",
    "data.loc[:, \"Dataset\"] = data[\"Dataset\"].map(\n",
    "    {\n",
    "        \"mnli_aug_rate0\": \"MNLI\",\n",
    "        \"mnli_mem_rate0\": \"MNLI\",\n",
    "        \"mnli\": \"MNLI\",\n",
    "        \"sst2_sc_rate0558\": \"SST2\",\n",
    "        \"sst2_mem_rate0\": \"SST2\",\n",
    "        \"mnli_sc_rate0354\": \"MNLI\",\n",
    "        \"sst2_aug_rate0\": \"SST2\",\n",
    "        \"sst2\": \"SST2\",\n",
    "        \"flickr\": \"flickr\",\n",
    "        \"ogbn-arxiv\": \"arXiv\",\n",
    "        \"cora\": \"Cora\",\n",
    "        \"in100\": \"IN100\"\n",
    "    }\n",
    ")\n",
    "data.loc[:, \"Setting\"] = data[\"Setting\"].map(\n",
    "    {\n",
    "        \"aug\": \"Augmentation\",\n",
    "        \"mem\": \"Random Labels\",\n",
    "        \"correlationJSD\": \"JSD Corr.\",\n",
    "        \"correlationAbsoluteAccDiff\": \"Acc Corr.\",\n",
    "        \"correlationDisagreement\": \"Disagr. Corr.\",\n",
    "        \"acc_corr\": \"Acc Corr.\",\n",
    "        \"mono\": \"Layer Mono.\",\n",
    "        \"sc\": \"Shortcuts\",\n",
    "    }\n",
    ")\n",
    "\n",
    "data.loc[:, \"Quality Measure\"] = data[\"Quality Measure\"].map(\n",
    "    {\"violation_rate\": \"Conformity Rate\", \"AUPRC\": \"AUPRC\", \"spearmanr\": \"Spearman\", \"correlation\": \"Spearman\"}\n",
    ")\n",
    "data.loc[data[\"Quality Measure\"] == \"Conformity Rate\", \"value\"] = (\n",
    "    1 - data.loc[data[\"Quality Measure\"] == \"Conformity Rate\", \"value\"]\n",
    ")  # must be run in conjunction with the above renaming\n",
    "\n",
    "data = data.rename(\n",
    "    columns={\n",
    "        \"domain\": \"Modality\",\n",
    "        \"architecture\": \"Arch.\",\n",
    "        \"Representational Similarity Measure\": \"Sim Meas.\",\n",
    "        \"Quality Measure\": \"Eval.\",\n",
    "        \"Setting\": \"Scenario\",\n",
    "    }\n",
    ")\n",
    "\n",
    "data = data.sort_values(by=[\"Sim Meas.\"])\n",
    "\n",
    "sns.set_theme(\"paper\", style=\"white\", font_scale=1.5)\n",
    "\n",
    "\n",
    "sns.catplot(data=data, x=\"rank\", y=\"Sim Meas.\", hue=\"Modality\", kind=\"bar\", height=10, aspect=0.5, col=\"Modality\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ranks = data.groupby([\"Modality\", \"Sim Meas.\"])[\"rank\"].agg([\"mean\", \"median\"]).reset_index()\n",
    "avg_ranks = avg_ranks.rename(columns={\"mean\": \"avg_rank\", \"median\": \"med_rank\"})\n",
    "avg_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.merge(data, avg_ranks).sort_values(by=[\"med_rank\"])\n",
    "for mod in plot_data.Modality.unique():\n",
    "    g = sns.catplot(\n",
    "        data=plot_data[plot_data.Modality == mod],\n",
    "        y=\"rank\",\n",
    "        x=\"Sim Meas.\",\n",
    "        hue=\"Modality\",\n",
    "        kind=\"box\",\n",
    "        height=5,\n",
    "        aspect=2,\n",
    "        col=\"Modality\",\n",
    "        palette={\"Language\": \"C1\", \"Vision\": \"C2\", \"Graph\": \"C0\"},\n",
    "        legend=False,\n",
    "    )\n",
    "    ax = g.axes[0, 0]\n",
    "    ax.tick_params(axis=\"x\", labelrotation=40)\n",
    "    xlabels = ax.get_xticklabels()\n",
    "    ax.set_xticklabels(xlabels, rotation=40, ha=\"right\")\n",
    "    ax.set_ylabel(\"Rank\")\n",
    "    ax.set_xlabel(\"Similarity Measures\")\n",
    "    if mod == \"Graph\":\n",
    "        ax.set_title(\"Graphs\")\n",
    "    else:\n",
    "        ax.set_title(mod)\n",
    "    g.savefig(f\"../../figs/aggregated_hor_{mod}.pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "    g = sns.catplot(\n",
    "        data=plot_data[plot_data.Modality == mod],\n",
    "        x=\"rank\",\n",
    "        y=\"Sim Meas.\",\n",
    "        hue=\"Modality\",\n",
    "        kind=\"box\",\n",
    "        height=7,\n",
    "        aspect=0.8,\n",
    "        col=\"Modality\",\n",
    "        palette={\"Language\": \"C1\", \"Vision\": \"C2\", \"Graph\": \"C0\"},\n",
    "        legend=False\n",
    "    )\n",
    "    ax = g.axes[0, 0]\n",
    "    ax.set_xlabel(\"Rank\")\n",
    "    ax.set_ylabel(\"Similarity Measures\")\n",
    "    if mod == \"Graph\":\n",
    "        ax.set_title(\"Graphs\")\n",
    "    else:\n",
    "        ax.set_title(mod)\n",
    "    g.savefig(f\"../../figs/aggregated_ver_{mod}.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
